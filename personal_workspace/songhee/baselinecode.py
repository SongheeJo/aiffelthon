# -*- coding: utf-8 -*-
"""baselinecode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QNB_1QcoZBF5RGDAJnAyxMLW3w3dfVHX
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import seaborn as sns
import librosa.display
import librosa as lb
import soundfile as sf

import os
import sys
print(sys.version)

"""# 1. Load data

## (1) 라벨
"""

# patient id별 진단명이 담긴 csv파일 열이름 pid, disease로 붙여서 불러오기
patient_data = pd.read_csv('/content/drive/MyDrive/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv',names=['pid','disease'])

patient_data.head()

df=pd.read_csv('/content/drive/MyDrive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/160_1b3_Al_mc_AKGC417L.txt',sep='\t')
df.head()

# 텍스트 파일 안의 값이 tap으로 구분 -> sep = '\t'

# 위 txt파일은 (Start , End ( time of respiratory cycles) ,crackles,weezels) 정보가 담겨있음 - 중요하므로 추출 
import os
path = '/content/drive/MyDrive/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'
files = [s.split('.')[0] for s in os.listdir(path) if '.txt' in s] # .아래(확장자) 빼고 제목만 리스트로 가져옴
files[:5]

def getFilenameInfo(file):
  return file.split('_')

getFilenameInfo('160_1b3_Al_mc_AKGC417L')

# .txt파일과 파일 제목으로 df만들기
files_data = []
for file in files:
  data=pd.read_csv(path + file + '.txt', sep = '\t', names=['start', 'end', 'crackles', 'weezels'])
  name_data = getFilenameInfo(file)
  data['pid']=name_data[0] # pid? patient id
  data['mode']=name_data[-2]
  data['filename']=file
  files_data.append(data)
files_df=pd.concat(files_data)
files_df.reset_index()
files_df.head()

patient_data.info() # 126는 고유값 개수가 아니라 그냥 열 갯수겠지?

files_df.info()

# pid를 기준으로 두 가지 데이터 프레임 (patient_data와 files_df) 하나로 합치기

patient_data.pid.dtype

files_df.pid.dtype # '0'은 뭐지?

# merge를 위해 자료형을 같게
patient_data.pid=patient_data.pid.astype('int32')

files_df.pid = files_df.pid.astype('int32')

data=pd.merge(files_df,patient_data,on='pid')
data.head()

'''
os.makedirs('csv_data')  # 디렉토리를 만들어다가 
data.to_csv('csv_data/data.csv', index=False) # 합친 df을 data.csv이름으로 저장
'''

"""## (2) 사운드 파일
6초로 잘라서 가져오기
"""

def getPureSample(raw_data, start, end, sr=22050):
  '''
  Takes a numpy array(=첫 번째 인자) and splits its using start and end args(=두, 세번째 인자) # 인자가 어떻게 들어가있나 확인해보자 => 마지막에서 두 번째 셀

  raw_data = numpy array of audio sample # 찍어보자 => 마지막 셀
  start=time
  end=time
  sr=sampling_rate
  mono=mono/stereo
  '''
  max_ind = len(raw_data) # ind는 index
  # min, max() 이유 - 잘못 기록된 것도 있을 수 있기 때문에!
  start_ind = min(int(start * sr), max_ind) 
  end_ind = min(int(end * sr), max_ind)
  return raw_data[start_ind: end_ind]

  # start와 raw_data를 맞춰주기 위해서 이미 샘플링 된 배열 데이터인 raw_data처럼 start에도 sampling rate을 곱해준다. 
  # 'we multiplied start with sampling rate cause start is time and raw_data is array sampled acc. to sampling rate'
  # <-- acc는 뭐지?

# 모델에 넣을 input의 크기는 같아야 됨 -> length (=start-end) 맞춰주기 필요 -> 길이가 얼마가 되야(몇 초여야) 베스트일까?
# 산점도 - 데이터 분포 파악
sns.scatterplot(x=(data.end-data.start), y=data.pid)

# 박스플롯 - 범주형 데이터의 분포를 파악
sns.boxplot(y=(data.end-data.start))

"""=> length로 ~6을 잡는 게 베스트로 보임.
==> 6이하일경우에는 제로패딩
==> 6이상일경우는 어떻게..??

"""

'''
os.makedirs('processed_audio_files')
# 이제 아래 작업을 하기 위해서 폴더를 하나 만든다.
'''

# 열마다 접근해서 호흡 사이클이 여러개인 데이터는 쪼개는 작업을 해주자.
# 일단 어떤 식으로 변수에 저장이 되는지를 print로 찍어서 확인해보자.
for index, row in data.iterrows():
  print("Index ->", index)
  print("Data->\n", row)
  break

'''
# 이 셀은 중요

i,c=0,0
for index,row in data.iterrows(): # interrows() 함수 - index는 index변수, 열은 series로 row변수에 저장
    maxLen=6    # 6초
    start=row['start']    # row['열이름'] - 행별 특정 칼럼의 값에 반복해서 접근
    end=row['end']
    filename=row['filename']  # 'start', 'end', 'filename'열에의 정보만 각각의 변수에 저장
    
    # if len > maxLen, change it to maxLen => 그냥 짤라버리네? ㄷㄷ 나중에 추가작업을 해주는 거겠지?
    if end-start>maxLen:
        end=start+maxLen
    
    audio_file_loc=path + filename + '.wav'
    
    if index > 0:
        # 한 환자에게서 얻어진 데이터에 한 사이클보다 많은 사이클이 존재하는지 확인 -> true) filename에 i 표시
        if data.iloc[index-1]['filename']==filename:
            i+=1
        else:
            i=0
    filename= filename + '_' + str(i) + '.wav'
    
    save_path='processed_audio_files/' + filename
    c+=1
    
    audioArr,sampleRate=lb.load(audio_file_loc, mono=True) # mono로 불러오기 # 인자로 리샘플 가능
    pureSample=getPureSample(audioArr,start,end,sampleRate) # min, max() 비교를 통해 보다 정확한 start, end time을 구하는 과정을 거친 raw_data
    
    # pad audio if pureSample len < max_len
    reqLen=6*sampleRate
    padded_data = lb.util.pad_center(pureSample, reqLen) # zero 패딩
    
    sf.write(file=save_path,data=padded_data,samplerate=sampleRate) # soundfile
print('Total Files Processed: ',c)


# Error opening 'processed_audio_files/160_1b3_Al_mc_AKGC417L_0.wav': System error. 
'''

# print(audioArr)

# print(sampleRate)

"""# 2. Pre-processing"""

path_data3 = '/content/drive/MyDrive/processed_audio_files_no_pad/'

audio_file_loc=path_data3 + row['filename'] + '_' + str(i) + '.wav'
audioArr,sampleRate=lb.load(audio_file_loc, mono=True) # mono로 불러오기 # 인자로 리샘플 가능

print(audioArr)

print(sampleRate)

# resampling 방법2

re_sampleRate = 4000
data_preprocessed = lb.resample(audioArr, sampleRate, re_sampleRate)

"""# 3. Train_val_test_split

## (1) Handling Class Imbalance
"""

# patient id별 진단명이 담긴 csv파일 열이름 pid, disease로 붙여서 불러오기
diagnosis=pd.read_csv('/content/drive/MyDrive/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv',names=['pid','disease'])
diagnosis.head()

# 데이터셋이 불균형하게 분포되어있는가를 확인하기 위해 클래스별로 데이터 개수를 세는 막대그래프 그리기
sns.countplot(diagnosis.disease) # 빈도그래프 - 각 범주에 속하는 데이터의 개수를 막대그래프로 나타내기
plt.xticks(rotation=90) # x축 눈금 표시

import os # operating system. 운영체제와의 상호작용을 돕는 라이브러리
def extractId(filename):
    return filename.split('_')[0] # 파일네임중 _기준 첫번째 부분(Id) 반환

# we got a /content/drive/MyDrive/processed.gsheet = merged df (thx to 정인)
'''
path='/content/drive/MyDrive/processed_audio_files' # 6초로 길이를 맞추고 sampling을 한 배열 형태의 사운드 파일이 저장된 폴더 # 이건 슬래시를 안그어도 돌아가네..?
length=len(os.listdir(path)) # os.listdir() - (특정 경로) 내에 존재하는 폴더와 파일 리스트 검색
index=range(length)
i=0
files_df=pd.DataFrame(index=index,columns=['pid','filename']) # 2번째 df 만들기 using 파일이름
for f in os.listdir(path):
    files_df.iloc[i]['pid']=extractId(f)
    files_df.iloc[i]['filename']=f
    i+=1
files_df.head()
'''

'''
files_df.pid=files_df.pid.astype('int64') # pid열로 합치기 위해 형변환
'''

'''
data=pd.merge(files_df,diagnosis,on='pid')
data.head()
'''

sheet_url="https://docs.google.com/spreadsheets/d/1ughHksz5KWOlsL1fJIm4Qqj6mAvygkdz_TzTV-2c2wM/edit#gid=1070722979"
url_1 = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')
data = pd.read_csv(url_1)
data.head()

sns.countplot(data.disease)
plt.xticks(rotation=90)

"""## (2) train-val-test split
데이터 포인트를 랜덤으로 섞은 뒤 데이터셋을 훈련세트와 검증세트로 나눔
-> overfitting을 방지
"""

# train, val = 75:25
from sklearn.model_selection import train_test_split
Xtrain,Xval,ytrain,yval=train_test_split(data,data.disease,stratify=data.disease,random_state=42,test_size=0.25)

"""# 4. Augmentation"""

!pip install nlpaug
import nlpaug.augmenter.audio as naa
naa.SpeedAug()


'''
#**********************DATA AUGMENTAION***************************
#Creates a copy of each time slice, but stretches or contracts it by a random amount
def gen_augmented(original, sample_rate):
	# list of augmentors available from the nlpaug library
	augment_list = [
	#naa.CropAug(sampling_rate=sample_rate)
	naa.NoiseAug(),
	naa.SpeedAug(),
	naa.LoudnessAug(factor=(0.5, 2)),
	naa.VtlpAug(sampling_rate=sample_rate, zone=(0.0, 1.0)),
	naa.PitchAug(sampling_rate=sample_rate, factor=(-1,3))
	]
	# sample augmentation randomly
	aug_idx = random.randint(0, len(augment_list)-1)
	augmented_data = augment_list[aug_idx].augment(original)
	return augmented_data
'''

"""# 5. Feature Extraction
리브로사의 feture extraction 방식을 써보자! + 1-by-1으로 각각의 성능을 확인하자!

## (1) 데이터 가져오기
"""

data

'''
train = pd.read_csv('/content/drive/MyDrive/train.csv')
val= pd.read_csv('/content/drive/MyDrive/val.csv')
train.head()
'''

'''
ytrain = train.disease # 훈련세트의 정답(레이블)
yval = val.disease # 검증세트의 정답(레이블)
yval
'''

ytrain

# LabelEncoder - object인 레이블(정답)의 자료형을 모델에 넣기 위해 숫자로 변환
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
ytrain = le.fit_transform(ytrain)
yval = le.transform(yval)

"""## (2) 추출"""

def getFeatures(path):
    soundArr,sample_rate=lb.load(path)
    mfcc=lb.feature.mfcc(y=soundArr,sr=sample_rate) # 오디오 데이터에서 특성을 뽑는 가장 대표적인 방법
    cstft=lb.feature.chroma_stft(y=soundArr, sr=sample_rate) # 특성 추출 방법2
    mSpec=lb.feature.melspectrogram(y=soundArr, sr=sample_rate) # 특성 추출 방법3 - 스펙트로그램에 인간의 귀가 주파수 대역이 높고 낮음에 따라 소리를 둔하게/민감하게 받아들이는 정도를 반영하는 mel-scale을 적용하여 구하는 mel-filter bank라는 필터를 적용해서 얻음

    return mfcc, cstft, mSpec

# to these function,

# mSpec만 뽑아보자.
# train, val셋 iteration - lb.featureextraction 
# val 셋

mSpec = []
i = 0
for idx, row in val.
mSpec_val=np.array(mSpec)

'''
# train, val셋 iteration - lb.featureextraction 
# val 셋
root='/content/drive/MyDrive/processed_audio_files/'
mfcc,cstft,mSpec=[],[],[]
i=0
for idx, row in val.iterrows():
    path=root + row['filename']
    a,b,c=getFeatures(path)
    mfcc.append(a)
    cstft.append(b)
    mSpec.append(c)

mfcc_val=np.array(mfcc)
cstft_val=np.array(cstft)
mSpec_val=np.array(mSpec)
'''

'''
print(mfcc_val) # append의 결과가 궁금하다.
'''

'''
# train 셋
root='/content/drive/MyDrive/processed_audio_files/'
mfcc,cstft,mSpec=[],[],[]
i=0
for idx,row in train.iterrows():
    path=root + row['filename']
    a,b,c=getFeatures(path)
    mfcc.append(a)
    cstft.append(b)
    mSpec.append(c)
    
mfcc_train=np.array(mfcc)
cstft_train=np.array(cstft)
mSpec_train=np.array(mSpec)
'''

"""# 6. Build model"""

'''합성곱 신경망 만들기'''

images = input_data.read_data_sets('MNIST_data', one_hot=True, reshape=False)

MODEL = keras.Sequential()

model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28,28,1))) # kernel, input shape 수치값 이해~~~

"""# 7. Evaluate"""